{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from isort import file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data_from_url(url, filename):\n",
    "    \"\"\"\n",
    "    Downloads data from the given URL and saves it to the specified file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the data to be downloaded.\n",
    "        filename (str): The name of the file to save the downloaded data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        response = requests.get(url)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "def extract_data(filename):\n",
    "    \"\"\"\n",
    "    Extracts relevant columns from a CSV file containing job data.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the filtered job data.\n",
    "    \"\"\"\n",
    "    jobs_data = pd.read_csv(filename)\n",
    "    columns_of_interest = [\n",
    "        \"job_title_short\", \"job_location\", \"job_via\", \"job_schedule_type\",\n",
    "        \"job_work_from_home\", \"job_posted_date\", \"job_skills\", \"job_country\", \"search_location\", \"company_name\",\n",
    "        \"job_title\", 'salary_year_avg', 'job_no_degree_mention', 'job_health_insurance','job_type_skills'\n",
    "    ]\n",
    "    jobs_data_filtered = jobs_data[columns_of_interest]\n",
    "    return jobs_data_filtered\n",
    "\n",
    "def preprocess_data(jobs_data):\n",
    "    \"\"\"\n",
    "    Preprocesses the job data by filling missing values, converting data types, creating new columns,\n",
    "    and encoding categorical variables.\n",
    "\n",
    "    Args:\n",
    "        jobs_data (pandas.DataFrame): The input job data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The preprocessed job data.\n",
    "    \"\"\"\n",
    "    jobs_data['job_work_from_home'] = jobs_data['job_work_from_home'].fillna(True)\n",
    "    jobs_data['salary_year_avg'] = jobs_data['salary_year_avg'].fillna(0)\n",
    "    jobs_data['job_posted_date'] = pd.to_datetime(jobs_data['job_posted_date'], errors='coerce').dt.date\n",
    "    jobs_data['job_title'] = jobs_data['job_title'].fillna('').astype(str)\n",
    "    jobs_data['job_title_short'] = jobs_data['job_title_short'].fillna('').astype(str)\n",
    "\n",
    "    # Define experience levels and their corresponding keywords\n",
    "    experience_levels = {\n",
    "        \"Entry\": [\"entry level\", \"junior\", \"intern\"],\n",
    "        \"Mid\": [\"mid level\", \"mid-level\", \"associate\"],\n",
    "        \"Senior\": [\"senior\", \"lead\", \"principal\", \"manager\"],\n",
    "        \"Director\": [\"director\", \"head\"],\n",
    "        \"Executive\": [\"executive\", \"vp\", \"vice president\", \"cxo\", \"ceo\", \"cto\", \"cfo\"]\n",
    "    }\n",
    "\n",
    "    def get_experience_level(title):\n",
    "        \"\"\"\n",
    "        Determines the experience level based on the job title.\n",
    "\n",
    "        Args:\n",
    "            title (str): The job title.\n",
    "\n",
    "        Returns:\n",
    "            str: The experience level.\n",
    "        \"\"\"\n",
    "        for level, keywords in experience_levels.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword.lower() in title.lower():\n",
    "                    return level\n",
    "        return \"Entry\"\n",
    "\n",
    "    jobs_data['experience_level'] = jobs_data['job_title'].apply(get_experience_level)\n",
    "\n",
    "    exp_level_abbr = {\n",
    "        \"Entry\": \"E\",\n",
    "        \"Mid\": \"M\",\n",
    "        \"Senior\": \"S\",\n",
    "        \"Director\": \"D\",\n",
    "        \"Executive\": \"X\"\n",
    "    }\n",
    "\n",
    "    def create_abbreviated_job_title(row):\n",
    "        \"\"\"\n",
    "        Creates an abbreviated job title based on the experience level.\n",
    "\n",
    "        Args:\n",
    "            row (pandas.Series): The row of the job data.\n",
    "\n",
    "        Returns:\n",
    "            str: The abbreviated job title.\n",
    "        \"\"\"\n",
    "        exp_level = row['experience_level']\n",
    "        if exp_level in exp_level_abbr:\n",
    "            return f\"{row['job_title_short']} ({exp_level_abbr[exp_level]})\"\n",
    "        return row['job_title_short']\n",
    "\n",
    "    jobs_data['abbreviated_job_title'] = jobs_data.apply(create_abbreviated_job_title, axis=1)\n",
    "\n",
    "    text_columns = ['job_title_short', 'job_location', 'job_via', 'job_schedule_type',\n",
    "                    'job_work_from_home', 'job_country', 'search_location', 'company_name', 'job_title']\n",
    "\n",
    "    for col in text_columns:\n",
    "        if jobs_data[col].dtype == 'object':\n",
    "            jobs_data[col] = jobs_data[col].str.lower().fillna('')\n",
    "        else:\n",
    "            jobs_data[col] = jobs_data[col].astype(str).str.lower().fillna('')\n",
    "\n",
    "    jobs_data['job_skills'] = jobs_data['job_skills'].apply(lambda x: json.loads(x.replace(\"'\", '\"')) if pd.notnull(x) else [])\n",
    "    jobs_data['job_type_skills'] = jobs_data['job_type_skills'].apply(lambda x: json.loads(x.replace(\"'\", '\"')) if pd.notnull(x) else {})\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    job_skills_encoded = mlb.fit_transform(jobs_data['job_skills'])\n",
    "    job_skills_df = pd.DataFrame(job_skills_encoded, columns=mlb.classes_)\n",
    "    jobs_data = pd.concat([jobs_data, job_skills_df], axis=1)\n",
    "\n",
    "    skill_types = jobs_data['job_type_skills'].apply(lambda x: list(x.keys()))\n",
    "    unique_types = list(set([item for sublist in skill_types for item in sublist]))\n",
    "    for skill_type in unique_types:\n",
    "        jobs_data[skill_type] = jobs_data['job_type_skills'].apply(lambda x: ','.join(x[skill_type]) if skill_type in x else '')\n",
    "\n",
    "    for skill_type in unique_types:\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        skills_encoded = mlb.fit_transform(jobs_data[skill_type].apply(lambda x: x.split(',')))\n",
    "        skills_df = pd.DataFrame(skills_encoded, columns=[f\"{skill_type}_{skill}\" for skill in mlb.classes_])\n",
    "        jobs_data = pd.concat([jobs_data, skills_df], axis=1)\n",
    "        jobs_data = jobs_data.drop(skill_type, axis=1)\n",
    "\n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(report, json_filename, html_filename):\n",
    "    \"\"\"\n",
    "    Generate a report in JSON and HTML format based on the given data.\n",
    "\n",
    "    Args:\n",
    "        report (dict): The data for generating the report.\n",
    "        json_filename (str): The filename for the JSON report.\n",
    "        html_filename (str): The filename for the HTML report.\n",
    "    \"\"\"\n",
    "    # Generate JSON report\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    def dict_to_html_table(data, title, sort_and_limit=False):\n",
    "        def nested_dict_to_table(nested_data):\n",
    "            \"\"\"\n",
    "            Converts a nested dictionary into an HTML table.\n",
    "\n",
    "            Args:\n",
    "                nested_data (dict): The nested dictionary to be converted.\n",
    "\n",
    "            Returns:\n",
    "                str: The HTML table representation of the nested dictionary.\n",
    "            \"\"\"\n",
    "            if isinstance(nested_data, dict):\n",
    "                headers = \"\".join([f\"<th>{key}</th>\" for key in nested_data.keys()])\n",
    "                values = \"\".join([f\"<td>{value}</td>\" for value in nested_data.values()])\n",
    "                return f\"<table><thead><tr>{headers}</tr></thead><tbody><tr>{values}</tr></tbody></table>\"\n",
    "            else:\n",
    "                return str(nested_data)\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            if sort_and_limit:\n",
    "                # Sort the dictionary by value in descending order and take top 10\n",
    "                sorted_data = dict(sorted(data.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "            else:\n",
    "                sorted_data = data\n",
    "            \n",
    "            headers = \"<th>Key</th><th>Value</th>\"\n",
    "            rows = \"\".join([f\"<tr><td>{key}</td><td>{nested_dict_to_table(value)}</td></tr>\" for key, value in sorted_data.items()])\n",
    "        elif isinstance(data, list):\n",
    "            headers = \"<th>Index</th><th>Value</th>\"\n",
    "            rows = \"\".join([f\"<tr><td>{index}</td><td>{nested_dict_to_table(value)}</td></tr>\" for index, value in enumerate(data)])\n",
    "        else:\n",
    "            return f\"<p>{data}</p>\"\n",
    "\n",
    "        return f\"\"\"\n",
    "        <div class=\"table-container\">\n",
    "            <h2>{title}</h2>\n",
    "            <div class=\"table-wrapper\">\n",
    "                <table>\n",
    "                    <thead><tr>{headers}</tr></thead>\n",
    "                    <tbody>{rows}</tbody>\n",
    "                </table>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    # Generate HTML report\n",
    "    html_content = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Job Data Analysis Report</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                line-height: 1.6;\n",
    "                padding: 20px;\n",
    "                max-width: 1200px;\n",
    "                margin: 0 auto;\n",
    "            }}\n",
    "            h1 {{ color: #333; }}\n",
    "            h2 {{ color: #666; }}\n",
    "            .table-container {{\n",
    "                margin-bottom: 30px;\n",
    "            }}\n",
    "            .table-wrapper {{\n",
    "                overflow-x: auto;\n",
    "                max-height: 500px;\n",
    "                overflow-y: auto;\n",
    "            }}\n",
    "            table {{\n",
    "                border-collapse: collapse;\n",
    "                width: 100%;\n",
    "            }}\n",
    "            th, td {{\n",
    "                border: 1px solid #ddd;\n",
    "                padding: 8px;\n",
    "                text-align: left;\n",
    "            }}\n",
    "            thead {{\n",
    "                position: sticky;\n",
    "                top: 0;\n",
    "                background-color: #f2f2f2;\n",
    "            }}\n",
    "            th {{\n",
    "                background-color: #f2f2f2;\n",
    "            }}\n",
    "            tr:nth-child(even) {{\n",
    "                background-color: #f9f9f9;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Job Data Analysis Report</h1>\n",
    "        {dict_to_html_table(report['Descriptive Statistics'], 'Descriptive Statistics')}\n",
    "        {dict_to_html_table(report['Average Salary by Location'], 'Average Salary by Location (Top 10)', sort_and_limit=True)}\n",
    "        {dict_to_html_table(report['Job Counts by Company'], 'Job Counts by Company (Top 10)', sort_and_limit=True)}\n",
    "        {dict_to_html_table(report['Experience Level Analysis'], 'Experience Level Analysis')}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    with open(html_filename, 'w') as f:\n",
    "        f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_serializable(obj):\n",
    "    \"\"\"\n",
    "    Helper function to make an object JSON serializable.\n",
    "\n",
    "    Args:\n",
    "        obj: The object to be made JSON serializable.\n",
    "\n",
    "    Returns:\n",
    "        The JSON serializable representation of the object.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return obj.to_dict()\n",
    "    elif isinstance(obj, pd.DataFrame):\n",
    "        return obj.to_dict(orient='records')\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "def make_hashable(item):\n",
    "    \"\"\"\n",
    "    Convert unhashable types within a list or dict to hashable types.\n",
    "\n",
    "    Args:\n",
    "        item: The item to be converted.\n",
    "\n",
    "    Returns:\n",
    "        The hashable representation of the item.\n",
    "    \"\"\"\n",
    "    if isinstance(item, list):\n",
    "        return tuple(make_hashable(x) for x in item)\n",
    "    elif isinstance(item, dict):\n",
    "        return frozenset((key, make_hashable(value)) for key, value in item.items())\n",
    "    return item\n",
    "\n",
    "def perform_data_quality_checks(df):\n",
    "    \"\"\"\n",
    "    Perform automated data quality checks on the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "        The input dataframe to perform data quality checks on.\n",
    "\n",
    "    Returns:\n",
    "    - dict\n",
    "        A dictionary containing the results of the data quality checks. The dictionary has the following structure:\n",
    "        {\n",
    "            \"missing_values\": {},\n",
    "            \"data_types\": {},\n",
    "            \"outliers\": {},\n",
    "            \"inconsistencies\": {},\n",
    "            \"value_ranges\": {}\n",
    "        }\n",
    "        - \"missing_values\": dict\n",
    "            A dictionary where the keys are column names and the values are the number of missing values in each column.\n",
    "        - \"data_types\": dict\n",
    "            A dictionary where the keys are column names and the values are the data types of each column.\n",
    "        - \"outliers\": dict\n",
    "            A dictionary where the keys are column names and the values are the number of outliers in each numerical column.\n",
    "        - \"inconsistencies\": dict\n",
    "            A dictionary where the keys are column names and the values are the inconsistencies found in each categorical column.\n",
    "        - \"value_ranges\": dict\n",
    "            A dictionary where the keys are column names and the values are dictionaries containing the minimum, maximum, mean, and median values of each numerical column.\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        \"missing_values\": {},\n",
    "        \"data_types\": {},\n",
    "        \"outliers\": {},\n",
    "        \"inconsistencies\": {},\n",
    "        \"value_ranges\": {}\n",
    "    }\n",
    "\n",
    "    # Preprocess columns containing unhashable types\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Convert lists and dicts to hashable types\n",
    "            df[col] = df[col].apply(lambda x: make_hashable(x) if isinstance(x, (list, dict)) else x)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    report[\"missing_values\"] = json_serializable(missing_values[missing_values > 0])\n",
    "\n",
    "    # Check data types\n",
    "    report[\"data_types\"] = json_serializable(df.dtypes.astype(str))\n",
    "\n",
    "    # Check for outliers in numerical columns\n",
    "    numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_columns:\n",
    "        z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "        outliers = df[col][z_scores > 3]\n",
    "        if not outliers.empty:\n",
    "            report[\"outliers\"][col] = len(outliers)\n",
    "\n",
    "    # Check for inconsistencies in categorical columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            unique_values = df[col].dropna().unique()\n",
    "            unique_count = len(unique_values)\n",
    "            \n",
    "            if unique_count == 1:\n",
    "                report[\"inconsistencies\"][col] = f\"Only one unique value: {unique_values[0]}\"\n",
    "            elif unique_count > 100:\n",
    "                report[\"inconsistencies\"][col] = f\"High cardinality: {unique_count} unique values\"\n",
    "\n",
    "    # Check value ranges for numerical columns\n",
    "    for col in numerical_columns:\n",
    "        report[\"value_ranges\"][col] = {\n",
    "            \"min\": json_serializable(df[col].min()),\n",
    "            \"max\": json_serializable(df[col].max()),\n",
    "            \"mean\": json_serializable(df[col].mean()),\n",
    "            \"median\": json_serializable(df[col].median())\n",
    "        }\n",
    "\n",
    "    return report\n",
    "\n",
    "def generate_data_quality_report(report, filename):\n",
    "    \"\"\"\n",
    "    Generate an HTML report for data quality checks with simple table formatting.\n",
    "    \"\"\"\n",
    "    def dict_to_html_table(data):\n",
    "        html = \"<table border='1'><tr><th>Key</th><th>Value</th></tr>\"\n",
    "        for key, value in data.items():\n",
    "            html += f\"<tr><td>{key}</td><td>{value}</td></tr>\"\n",
    "        html += \"</table>\"\n",
    "        return html\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Data Quality Report</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            h2 {{ color: #666; }}\n",
    "            table {{ border-collapse: collapse; width: 100%; }}\n",
    "            th, td {{ text-align: left; padding: 8px; }}\n",
    "            tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Data Quality Report</h1>\n",
    "        <h2>Missing Values</h2>\n",
    "        {dict_to_html_table(report['missing_values'])}\n",
    "        <h2>Data Types</h2>\n",
    "        {dict_to_html_table(report['data_types'])}\n",
    "        <h2>Outliers</h2>\n",
    "        {dict_to_html_table(report['outliers'])}\n",
    "        <h2>Inconsistencies</h2>\n",
    "        {dict_to_html_table(report['inconsistencies'])}\n",
    "        <h2>Value Ranges</h2>\n",
    "        {dict_to_html_table({k: str(v) for k, v in report['value_ranges'].items()})}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "def create_data_quality_report_widget(jobs_data, results_folder):\n",
    "    \"\"\"\n",
    "    Creates a widget for generating a data quality report.\n",
    "\n",
    "    Parameters:\n",
    "    - jobs_data (DataFrame): The input data for performing data quality checks.\n",
    "    - results_folder (str): The folder path where the data quality report will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - widget.VBox: The widget containing a button to generate the data quality report and an output area for displaying the report.\n",
    "    \"\"\"\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_generate_report(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Generating Data Quality Report...\")\n",
    "            data_quality_report = perform_data_quality_checks(jobs_data)\n",
    "            filename_quality_report = os.path.join(results_folder, 'data_quality_report.html')\n",
    "            generate_data_quality_report(data_quality_report, filename_quality_report)\n",
    "            print(\"Data quality report generated as data_quality_report.html\")\n",
    "            display(HTML('<a href=\"data_quality_report.html\" target=\"_blank\">Open Data Quality Report</a>'))\n",
    "\n",
    "    generate_button = widgets.Button(description=\"Generate Data Quality Report\")\n",
    "    generate_button.on_click(on_generate_report)\n",
    "\n",
    "    return widgets.VBox([generate_button, output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_skills(skills_string):\n",
    "    \"\"\"\n",
    "    Parses a string or list of skills and returns a list of stripped skills.\n",
    "\n",
    "    Args:\n",
    "        skills_string (str or list): The input string or list of skills.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of stripped skills.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> parse_skills('Python, Java, C++')\n",
    "        ['Python', 'Java', 'C++']\n",
    "\n",
    "        >>> parse_skills(['Python', 'Java', 'C++'])\n",
    "        ['Python', 'Java', 'C++']\n",
    "    \"\"\"\n",
    "    # If the input is already a list, return it as is after stripping elements\n",
    "    if isinstance(skills_string, list):\n",
    "        return [str(skill).strip() for skill in skills_string if skill]\n",
    "    \n",
    "    try:\n",
    "        # Try to parse the string as a list using literal_eval\n",
    "        skills_list = ast.literal_eval(skills_string)\n",
    "        return [str(skill).strip() for skill in skills_list if skill]\n",
    "    except (ValueError, SyntaxError):\n",
    "        # If parsing fails, treat it as a comma-separated string\n",
    "        return [skill.strip() for skill in skills_string.split(',') if skill.strip()]\n",
    "\n",
    "def job_recommendation_system(jobs_data, user_skills):\n",
    "    \"\"\"\n",
    "    Recommends jobs based on user's skills.\n",
    "\n",
    "    Args:\n",
    "        jobs_data (DataFrame): A DataFrame containing job data.\n",
    "        user_skills (list): A list of skills possessed by the user.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the top 10 recommended jobs based on skill match.\n",
    "    \"\"\"\n",
    "    jobs_data['skill_match'] = jobs_data['job_skills'].apply(lambda x: len(set(x) & set(user_skills)))\n",
    "    recommended_jobs = jobs_data.sort_values('skill_match', ascending=False).head(10)\n",
    "    return recommended_jobs\n",
    "\n",
    "def perform_comprehensive_analysis(jobs_data):\n",
    "    \"\"\"\n",
    "    Perform a comprehensive analysis on job market data.\n",
    "\n",
    "    Args:\n",
    "        jobs_data (DataFrame): The input job market data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the analysis report and the trained model.\n",
    "            The analysis report is a dictionary with the following keys:\n",
    "                - 'Descriptive Statistics': Descriptive statistics of the job market data.\n",
    "                - 'Average Salary by Location': Average salary by job location.\n",
    "                - 'Job Counts by Company': Number of jobs by company.\n",
    "                - 'Feature Importance': Feature importance of the trained model.\n",
    "                - 'Experience Level Analysis': Analysis of job data by experience level.\n",
    "            The trained model is a RandomForestRegressor model trained on the input data.\n",
    "    \"\"\"\n",
    "    # Function code here...\n",
    "    pass\n",
    "def perform_comprehensive_analysis(jobs_data):\n",
    "    # Ensure job_skills are parsed\n",
    "    jobs_data['job_skills'] = jobs_data['job_skills'].apply(parse_skills)\n",
    "\n",
    "    # Descriptive statistics\n",
    "    desc_stats = jobs_data.describe()\n",
    "    avg_salary_by_location = jobs_data.groupby('job_location')['salary_year_avg'].mean()\n",
    "    job_counts_by_company = jobs_data['company_name'].value_counts()\n",
    "\n",
    "    features = ['job_location', 'job_schedule_type', 'job_work_from_home', 'job_country', 'job_posted_date', 'experience_level']\n",
    "    X = jobs_data[features]\n",
    "    y = jobs_data['salary_year_avg']\n",
    "\n",
    "    label_encoders = {}\n",
    "    for col in X.select_dtypes(include=['object', 'datetime64']).columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Experience Level-Based Job Analysis\n",
    "    exp_level_analysis = jobs_data.groupby('experience_level').agg({\n",
    "        'salary_year_avg': ['mean', 'std'],\n",
    "        'job_title': 'count'\n",
    "    }).reset_index()\n",
    "    exp_level_analysis.columns = ['experience_level', 'avg_salary', 'salary_std', 'job_count']\n",
    "\n",
    "    report = {\n",
    "        'Descriptive Statistics': desc_stats.to_dict(),\n",
    "        'Average Salary by Location': avg_salary_by_location.to_dict(),\n",
    "        'Job Counts by Company': job_counts_by_company.to_dict(),\n",
    "        'Feature Importance': feature_importance.to_dict('records'),\n",
    "        'Experience Level Analysis': exp_level_analysis.to_dict('records')\n",
    "    }\n",
    "\n",
    "    return report, model\n",
    "\n",
    "def create_interactive_widgets(jobs_data, model):\n",
    "    \"\"\"\n",
    "    Creates interactive widgets for job recommendation and salary prediction.\n",
    "\n",
    "    Args:\n",
    "        jobs_data (pandas.DataFrame): DataFrame containing job data.\n",
    "        model: Trained machine learning model for salary prediction.\n",
    "\n",
    "    Returns:\n",
    "        output (widgets.Output): Output widget to display recommendations and predictions.\n",
    "    \"\"\"\n",
    "    # Job recommendation widgets\n",
    "    all_skills = set()\n",
    "    for skills in jobs_data['job_skills']:\n",
    "        all_skills.update(skills)\n",
    "    all_skills = {skill for skill in all_skills if isinstance(skill, str) and skill.isalpha() and len(skill) > 1}\n",
    "\n",
    "    skills_dropdown = widgets.SelectMultiple(\n",
    "        options=sorted(all_skills),\n",
    "        description='Skills:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    recommend_button = widgets.Button(description=\"Get Recommendations\")\n",
    "\n",
    "    # Experience level dropdown for salary prediction\n",
    "    experience_levels = jobs_data['experience_level'].unique()\n",
    "    exp_level_dropdown = widgets.Dropdown(\n",
    "        options=experience_levels,\n",
    "        description='Experience Level:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    predict_salary_button = widgets.Button(description=\"Predict Salary\")\n",
    "\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_recommend_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            user_skills = list(skills_dropdown.value)\n",
    "            if not user_skills:\n",
    "                print(\"Please select at least one skill.\")\n",
    "                return\n",
    "\n",
    "            recommended_jobs = job_recommendation_system(jobs_data, user_skills)\n",
    "            display(HTML(recommended_jobs[['job_title_short', 'job_location', 'job_via']].to_html(index=False)))\n",
    "\n",
    "    def on_predict_salary_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            exp_level = exp_level_dropdown.value\n",
    "            if not exp_level:\n",
    "                print(\"Please select an experience level.\")\n",
    "                return\n",
    "\n",
    "            # Get average values for other features\n",
    "            avg_features = jobs_data[['job_location', 'job_schedule_type', 'job_work_from_home', 'job_country']].mode().iloc[0]\n",
    "\n",
    "            # Prepare the input for prediction\n",
    "            input_data = pd.DataFrame({\n",
    "                'job_location': [avg_features['job_location']],\n",
    "                'job_schedule_type': [avg_features['job_schedule_type']],\n",
    "                'job_work_from_home': [avg_features['job_work_from_home']],\n",
    "                'job_country': [avg_features['job_country']],\n",
    "                'job_posted_date': [jobs_data['job_posted_date'].max()],\n",
    "                'experience_level': [exp_level]\n",
    "            })\n",
    "\n",
    "            # Transform categorical variables\n",
    "            for col in input_data.select_dtypes(include='object').columns:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(jobs_data[col])  # Fit on the entire dataset\n",
    "                input_data[col] = le.transform(input_data[col])\n",
    "\n",
    "            # Make prediction\n",
    "            predicted_salary = model.predict(input_data)[0]\n",
    "            \n",
    "            # Calculate confidence interval (assuming normal distribution)\n",
    "            confidence_interval = 1.96 * 7053.83  # 95% confidence interval\n",
    "\n",
    "            lower_bound = max(0, predicted_salary - confidence_interval)\n",
    "            upper_bound = predicted_salary + confidence_interval\n",
    "\n",
    "            print(f\"Predicted salary for {exp_level} experience level:\")\n",
    "            print(f\"${predicted_salary:.2f} (95% CI: ${lower_bound:.2f} - ${upper_bound:.2f})\")\n",
    "\n",
    "            # Show average salary from the dataset for comparison\n",
    "            avg_salary = jobs_data[jobs_data['experience_level'] == exp_level]['salary_year_avg'].mean()\n",
    "            print(f\"Average salary in dataset for {exp_level} experience level: ${avg_salary:.2f}\")\n",
    "\n",
    "    recommend_button.on_click(on_recommend_clicked)\n",
    "    predict_salary_button.on_click(on_predict_salary_clicked)\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([skills_dropdown, recommend_button]),\n",
    "        widgets.HBox([exp_level_dropdown, predict_salary_button]),\n",
    "        output\n",
    "    ]))\n",
    "\n",
    "    return output\n",
    "\n",
    "def display_full_report(report, output):\n",
    "    \"\"\"\n",
    "    Display the full job data analysis report.\n",
    "\n",
    "    Args:\n",
    "        report (dict): The job data analysis report containing various sections.\n",
    "        output (IPython.display.OutputWidget): The output widget to display the report.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        html_content = \"\"\"\n",
    "        <h1>Job Data Analysis Report</h1>\n",
    "        \n",
    "        <h2>Descriptive Statistics</h2>\n",
    "        {desc_stats}\n",
    "        \n",
    "        <h2>Average Salary by Location (Top 10)</h2>\n",
    "        {avg_salary}\n",
    "        \n",
    "        <h2>Job Counts by Company (Top 10)</h2>\n",
    "        {job_counts}\n",
    "        \n",
    "        <h2>Feature Importance</h2>\n",
    "        {feature_importance}\n",
    "        \n",
    "        <h2>Experience Level Analysis</h2>\n",
    "        {exp_analysis}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert each section to HTML\n",
    "        desc_stats_html = pd.DataFrame(report['Descriptive Statistics']).to_html()\n",
    "        avg_salary_html = pd.Series(report['Average Salary by Location']).sort_values(ascending=False).head(10).to_frame().to_html()\n",
    "        job_counts_html = pd.Series(report['Job Counts by Company']).sort_values(ascending=False).head(10).to_frame().to_html()\n",
    "        feature_importance_html = pd.DataFrame(report['Feature Importance']).to_html()\n",
    "        exp_analysis_html = pd.DataFrame(report['Experience Level Analysis']).to_html()\n",
    "        \n",
    "        # Format the HTML content\n",
    "        formatted_html = html_content.format(\n",
    "            desc_stats=desc_stats_html,\n",
    "            avg_salary=avg_salary_html,\n",
    "            job_counts=job_counts_html,\n",
    "            feature_importance=feature_importance_html,\n",
    "            exp_analysis=exp_analysis_html\n",
    "        )\n",
    "        \n",
    "        display(HTML(formatted_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data found as results/data_jobs_preprocessed_analysis.csv. Loading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae671ee96640fd808e2f7c3760d93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Generate Data Quality Report', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/c38fwrcx4d1cw1c5895pxnb40000gn/T/ipykernel_33969/3660770557.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive job analysis system is ready. Please use the dropdowns to select skills and experience level.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106e1e9c933e49639cd7683a99ec4fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(SelectMultiple(description='Skills:', options=('airflow', 'airtable', 'alteryx',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aee6755732f4d04b7f18e35d60c6380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Full Report', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    results_folder = \"results\"\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "    # Load and preprocess data (you need to implement this part)\n",
    "    url = \"https://huggingface.co/datasets/lukebarousse/data_jobs/resolve/main/data_jobs.csv?download=true\"\n",
    "        # Filepath to save the downloaded data\n",
    "    filename = os.path.join(results_folder, \"data_jobs.csv\")\n",
    "\n",
    "    # Check if data file exists, if not, download it\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading data from {url}...\")\n",
    "        print(f\"Saving data to {filename}...\")\n",
    "        load_data_from_url(url, filename)\n",
    "\n",
    "    # Check if preprocessed data file exists\n",
    "    preprocessed_filename = os.path.join(results_folder, \"data_jobs_preprocessed_analysis.csv\")\n",
    "    if os.path.exists(preprocessed_filename):\n",
    "        print(f\"Preprocessed data found as {preprocessed_filename}. Loading...\")\n",
    "        jobs_data_preprocessed = pd.read_csv(preprocessed_filename)\n",
    "    else:\n",
    "        print(preprocessed_filename)\n",
    "        # Extract and preprocess data\n",
    "        jobs_data_filtered = extract_data(filename)\n",
    "        jobs_data_preprocessed = preprocess_data(jobs_data_filtered)\n",
    "        jobs_data_preprocessed.to_csv(preprocessed_filename, index=False)\n",
    "        print(f\"Preprocessed data saved as {preprocessed_filename}\")\n",
    "\n",
    "    jobs_data_sampled = jobs_data_preprocessed.sample(n=20000, random_state=42)\n",
    "    # Perform data quality checks\n",
    "    data_quality_widget = create_data_quality_report_widget(jobs_data_sampled, results_folder)\n",
    "    display(data_quality_widget)\n",
    "    report, model = perform_comprehensive_analysis(jobs_data_sampled)\n",
    "    print(\"Interactive job analysis system is ready. Please use the dropdowns to select skills and experience level.\")\n",
    "    # Create and display interactive widgets\n",
    "    output = create_interactive_widgets(jobs_data_sampled, model)\n",
    "    # Create and display the full report button\n",
    "    full_report_button = widgets.Button(description=\"Show Full Report\")\n",
    "    full_report_button.on_click(lambda b: display_full_report(report, output))\n",
    "    display(full_report_button)\n",
    "    json_filename = os.path.join(results_folder,'job_data_analysis_report.json')\n",
    "    html_filename = os.path.join(results_folder,'job_data_analysis_report.html')\n",
    "    generate_report(report, json_filename, html_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
